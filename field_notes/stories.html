<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Work Stories | Jason Allred</title>
    <link rel="stylesheet" href="style.css?v=b00f6a9e">
</head>
<body>
    <button id="menu-toggle">☰ MENU</button>

    <nav id="sidebar">
        <mission-control></mission-control>

        <input type="text" id="nav-filter" placeholder="Filter nodes..." aria-label="Filter navigation">

        <div id="searchable-content">
            <h2>Systems Architecture</h2>
            <ul>
                <li><a href="#visa-tool">The VISA Tool Engine</a></li>
                <li><a href="#xslt-parsing">Automated Parsing (XSLT)</a></li>
                <li><a href="#config-file">A Simple Config File</a></li>
                <li><a href="#fleet-scale">Flashing 100 Nodes</a></li>
                <li><a href="#cygwin-wall">The Cygwin Wall</a></li>
                <li><a href="#ti-basic">Reinventing TI Basic</a></li>
                <li><a href="#quakecon">The QuakeCon Hot Swap</a></li>
            </ul>

            <h2>Validation Methodology</h2>
            <ul>
                <li><a href="#reading-robot">Reading Like a Robot</a></li>
                <li><a href="#rapl-matplotlib">RAPL & Matplotlib</a></li>
                <li><a href="#grok-code">How to Grok Code</a></li>
                <li><a href="#beating-heart">The Beating Heart</a></li>
                <li><a href="#serial-fragments">Expect Fragments (Serial)</a></li>
                <li><a href="#crazy-callbacks">Crazy Callbacks</a></li>
                <li><a href="#throughput-gotchas">Throughput Gotchas</a></li>
                <li><a href="#curl-postman">Curl over Postman</a></li>
                <li><a href="#venv-glue">Venv is like Hot Glue</a></li>
            </ul>

            <h2>Security & Yield</h2>
            <ul>
                <li><a href="#rakp-security">The RAKP Security Catch</a></li>
                <li><a href="#kernel-patch">The Kernel Patch</a></li>
                <li><a href="#negative-testing">Negative Testing (Yield)</a></li>
                <li><a href="#texas-power-on">The Texas Power-On</a></li>
                <li><a href="#failed-demo">The Failed Microsoft Demo</a></li>
                <li><a href="#rmcp-optimization">RMCP+ Socket Optimization</a></li>
            </ul>

            <h2>Engineering Leadership</h2>
            <ul>
                <li><a href="#scm-integration">To SCM or Not to SCM</a></li>
                <li><a href="#estimates">Estimates: High vs. Low</a></li>
                <li><a href="#pythonsv-thrash">The PythonSV API Thrash</a></li>
                <li><a href="#synergy">Synergy of Validation</a></li>
                <li><a href="#first-error">Always Fix the First Error</a></li>
                <li><a href="#count-oks">Count the Ok's</a></li>
                <li><a href="#conflict-management">The Conflict Management Lesson</a></li>
                <li><a href="#general-thoughts">General Thoughts & Philosophy</a></li>
            </ul>

            <h2>Future Work</h2>
            <ul>
                <li><a href="#future-work">WIP Items</a></li>
            </ul>
        </div>
    </nav>

    <main>
        <!-- SYSTEMS ARCHITECTURE -->
        <section id="architecture">
            <h2 class="section-title">Systems Architecture & Scale</h2>

            <article id="visa-tool">
                <h3>The VISA Tool Engine (Metadata-Driven Design)</h3>
                <div class="meta">Tag: Architecture | Impact: Maintenance Reduction</div>
                <p>I took over a complex debug tool where the logic for different CPU cores and steppings was becoming unmanageable through traditional hard-coding. By "grokking" the code to find its "beating heart," I realized the project could be re-architected as a metadata-driven engine centered on XML.</p>
                <p>I shifted the design so that the XML schema defined the GUI and silicon features—such as a checkbox to forward VISA signals over JTAG—allowing the tool to auto-detect and deploy functionality without any further code changes. <strong>This "Configuration as Code" approach allowed me to support years of new hardware iterations by simply updating XML definitions scraped directly from RTL.</strong></p>
            </article>

            <article id="xslt-parsing">
                <h3>Automated Parsing - The XSLT Experience</h3>
                <div class="meta">Tag: Automation | Impact: Efficiency</div>
                <p>Part of maintaining the VISA tool involved manually stitching together different silicon code blocks with their corresponding RTL flow so the signals would be available to the whole engine. The tool would allow you to select signal sources in the silicon and spit out JTAG commands to enable a direct connection to LA pins or the on-chip LA (OCLA).</p>
                <p>I developed an engine to directly convert RTL into XML compatible with the tool. This saved tremendous time and allowed a quick turnaround for new steppings and layouts. I also got some experience outside of linear code with XSLT.</p>
            </article>

            <article id="config-file">
                <h3>A Simple Config File</h3>
                <div class="meta">Tag: Quality of Life | Impact: Usability</div>
                <p>The VISA tool was also highly dependent on the stepping and family of a processor. Each new power-on of new silicon required me to re-compile the project and update the source code. Wary of this extra maintenance step I added a config file. It was a simple two-day fix that saved me about 2 hours per month, but also enabled anyone to add a project without my express involvement.</p>
                <p>My manager quietly wrote it down and later surprised me by praising me for forward thinking in my yearly focal. Since then I’ve learned value does not always correspond to effort, and gave me respect for simple QOL improvements.</p>
            </article>

            <article id="fleet-scale">
                <h3>Flashing 100 Nodes (Fleet Scale Operations)</h3>
                <div class="meta">Tag: Operations | Impact: Scale</div>
                <p>While in my PAE role, I maintained roughly 100 Knights Landing nodes that allowed us to reproduce issues with OEMs. Stuff you’d only see once in a million happened regularly when you start doing a million things quickly and in parallel. We used pdsh regularly. You think very differently about manually flashing BIOS when it needs to be done 100 times with a tough-to-reach harness.</p>
                <p>I eventually moved to standard production flows, but those pdsh days made me a better engineer by forcing me to think about failures at scale. It’s one thing to fix a BIOS; it’s another to fix a BIOS across a cluster.</p>
            </article>

            <article id="cygwin-wall">
                <h3>The Cygwin Wall (Environment Isolation)</h3>
                <div class="meta">Tag: Operations | Impact: Reliability</div>
                <p>One of my early challenges was managing complex validation environments on Windows machines. We were running a mix of Linux-based debug tools through Cygwin and native Windows drivers. The environment conflicts were a constant source of "ghost bugs."</p>
                <p>I learned to treat the validation environment as a "first-class citizen," strictly isolating dependencies and documenting environment setup as a BKM. This reduced setup time from 2 days to 2 hours for new hires.</p>
            </article>

            <article id="ti-basic">
                <h3>Reinventing TI Basic (The High School Genesis)</h3>
                <div class="meta">Tag: Origins | Impact: Career Foundation</div>
                <p>Before I ever worked on silicon, I was automating my high school chemistry class on a TI-83+ using TI-Basic. I wrote a solver for the periodic table that could handle molecular weight calculations and stoichiometry. It taught me the most important lesson in engineering: <strong>The computer is a tool to extend your own reach.</strong></p>
            </article>

            <article id="quakecon">
                <h3>The QuakeCon Hot Swap (Stress-Testing at Scale)</h3>
                <div class="meta">Tag: Stress Test | Impact: Field Recovery</div>
                <p>During my time supporting large-scale events, I had to perform live hardware maintenance on servers during peak load. It taught me the value of "Graceful Degradation" and how to maintain focus when the stakes (and temperatures) are high. You learn to trust your BKMs when the room is 90 degrees and 1000 people are using your network.</p>
            </article>
        </section>

        <!-- VALIDATION METHODOLOGY -->
        <section id="methodology">
            <h2 class="section-title">Validation Methodology</h2>

            <article id="reading-robot">
                <h3>Reading Like a Robot (Log Analysis)</h3>
                <div class="meta">Tag: Analysis | Impact: Root Cause Identification</div>
                <p>I’ve spent thousands of hours staring at hex dumps and serial fragments. The key to successful validation is knowing how to "mask out" the noise. I developed a mental framework for log triage: identify the heartbeat, find the first deviation, and map the causality loop.</p>
            </article>

            <article id="rapl-matplotlib">
                <h3>RAPL & Matplotlib (Telemetry Visualization)</h3>
                <div class="meta">Tag: Telemetry | Impact: Visual Debugging</div>
                <p>When debugging power management issues, raw numbers are often misleading. I built a pipeline using Python and Matplotlib to graph RAPL (Running Average Power Limit) data in real-time. This allowed us to see power "spikes" that were too fast for traditional sensors to catch, leading to a critical fix in the BIOS power-balancing logic.</p>
            </article>

            <article id="grok-code">
                <h3>How to Grok Code</h3>
                <div class="meta">Tag: Philosophy | Impact: Knowledge Acquisition</div>
                <p>Grokking is more than reading; it’s understanding the *intent* of the original engineer. I use a "Point of Failure" approach to new codebases: I try to break it in specific ways to see how the error handling responds. If the code screams in the right places, it’s well-architected.</p>
            </article>

            <article id="beating-heart">
                <h3>The Beating Heart (Identifying Core Logic)</h3>
                <div class="meta">Tag: Architecture | Impact: Maintenance</div>
                <p>Every complex system has a "beating heart"—a few hundred lines of code that handle the primary state machine. In the VISA tool, it was the JTAG sequencer. Once I isolated that, I could refactor the entire 50,000-line project without breaking the core mission.</p>
            </article>

            <article id="serial-fragments">
                <h3>Expect Fragments (Serial Debugging)</h3>
                <div class="meta">Tag: Low-Level | Impact: Diagnostic Accuracy</div>
                <p>Hardware debug ports are messy. They drop characters, they swap bits, and they stutter. I built a robust serial parser that could reconstruct fragmented JSON packets from a noisy BMC port, enabling us to get telemetry from boards that were technically "dead."</p>
            </article>

            <article id="crazy-callbacks">
                <h3>Crazy Callbacks (Asynchronous Validation)</h3>
                <div class="meta">Tag: Software | Impact: Performance</div>
                <p>I once inherited a validation suite that used nested callbacks seven levels deep. It was a race condition nightmare. I refactored the flow into a linear state machine using Python’s `asyncio`, which improved test reliability by 40% and made the code readable for the first time in years.</p>
            </article>

            <article id="throughput-gotchas">
                <h3>Throughput Gotchas</h3>
                <div class="meta">Tag: Performance | Impact: Optimization</div>
                <p>We once hit a "throughput wall" where our validation tools were slower than the silicon we were testing. I discovered a bottleneck in how we were writing to disk. By switching to memory-mapped files (mmap) and batching writes, we increased our telemetry capture rate by 10x.</p>
            </article>

            <article id="curl-postman">
                <h3>Curl over Postman</h3>
                <div class="meta">Tag: Philosophy | Impact: Efficiency</div>
                <p>I prefer raw tools. Postman is pretty, but `curl` is scriptable, repeatable, and lives in the terminal. If you can’t debug your API with a one-liner, you don't really own the protocol.</p>
            </article>

            <article id="venv-glue">
                <h3>Venv is like Hot Glue</h3>
                <div class="meta">Tag: Operations | Impact: Isolation</div>
                <p>Python virtual environments are the "Hot Glue" of modern validation. They allow you to stick together disparate tools without ruining your underlying system. I enforce a strict "One Tool, One Venv" policy to prevent dependency drift.</p>
            </article>
        </section>

        <!-- SECURITY & YIELD -->
        <section id="security">
            <h2 class="section-title">Security & Yield</h2>

            <article id="rakp-security">
                <h3>The RAKP Security Catch</h3>
                <div class="meta">Tag: Security | Impact: Vulnerability Mitigation</div>
                <p>During a routine manageability audit, I identified a flaw in how RAKP (Remote Authenticated Key Exchange Protocol) was being handled by a third-party BMC firmware. It allowed for potential credential interception. I developed a proof-of-concept exploit to demonstrate the risk, which led to a mandatory firmware update across the fleet.</p>
            </article>

            <article id="kernel-patch">
                <h3>The Kernel Patch (Upstream Contribution)</h3>
                <div class="meta">Tag: Low-Level | Impact: System Stability</div>
                <p>While validating a new Xeon platform, we found a kernel-level hang during heavy I/O stress tests. I narrowed it down to a driver conflict in the IRQ balancing logic. I submitted a patch to the internal kernel team that was eventually upstreamed, fixing the issue for all future iterations of that chip family.</p>
            </article>

            <article id="negative-testing">
                <h3>Negative Testing (The Yield King)</h3>
                <div class="meta">Tag: Methodology | Impact: Product Quality</div>
                <p>Positive testing proves it works; Negative testing proves it's robust. I specialize in "Invalid Opcode" testing—sending the silicon commands it *shouldn't* handle to ensure it fails gracefully rather than hanging the entire system. This is where real yield gains are found.</p>
            </article>

            <article id="texas-power-on">
                <h3>The Texas Power-On (Remote Recovery)</h3>
                <div class="meta">Tag: Resilience | Impact: Time Savings</div>
                <p>I once had to recover a bricked server in a Texas lab while I was in Oregon. Through a series of creative SSH tunnels and a lucky find in a BMC raw command manual, I managed to re-flash the BIOS without a physical presence. <strong>It taught me that connectivity is the ultimate debug tool.</strong></p>
            </article>

            <article id="failed-demo">
                <h3>The Failed Microsoft Demo (Learning from Scars)</h3>
                <div class="meta">Tag: Scar | Impact: Process Hardening</div>
                <p>The most important lessons come from failure. I once led a demo for a high-profile customer where the system crashed 5 minutes in due to a loose cable. Since then, my BKMs include a "Physical Integrity" check before any software validation begins. **You can't fix a loose pin with code.**</p>
            </article>

            <article id="rmcp-optimization">
                <h3>RMCP+ Socket Optimization</h3>
                <div class="meta">Tag: Security | Impact: Performance</div>
                <p>IPMI over RMCP+ is notoriously chatty. I optimized the handshake process in our validation suite to reduce latency by 200ms per command. When you're running 10,000 commands a day, those milliseconds add up to hours of saved time.</p>
            </article>
        </section>

        <!-- LEADERSHIP & PHILOSOPHY -->
        <section id="leadership">
            <h2 class="section-title">Engineering Leadership</h2>

            <article id="scm-integration">
                <h3>To SCM or Not to SCM</h3>
                <div class="meta">Tag: Philosophy | Impact: Team Velocity</div>
                <p>I advocate for Source Control Management (SCM) even for the "quick and dirty" scripts. If it isn't in Git, it didn't happen. I’ve rescued entire projects by simply being the one person who kept a history of "what worked yesterday."</p>
            </article>

            <article id="estimates">
                <h3>Estimates: High vs. Low</h3>
                <div class="meta">Tag: Leadership | Impact: Expectation Management</div>
                <p>In validation, everything takes twice as long as you think because the first half is spent fixing the tools. I teach my team to provide "Discovery Estimates" vs "Execution Estimates." This transparency builds trust with project managers.</p>
            </article>

            <article id="pythonsv-thrash">
                <h3>The PythonSV API Thrash</h3>
                <div class="meta">Tag: Scar | Impact: Design Resilience</div>
                <p>I’ve lived through multiple iterations of internal Intel APIs. I learned to build "Abstraction Layers" around my core logic so that when the underlying API changes (and it always does), I only have to update one file, not 500.</p>
            </article>

            <article id="synergy">
                <h3>Synergy of Validation</h3>
                <div class="meta">Tag: Leadership | Impact: Quality</div>
                <p>Validation isn't a separate phase; it's a parallel process. I work closely with design engineers to build "Hooks" into the silicon that make validation easier. **A chip that can't be tested is just a very expensive heater.**</p>
            </article>

            <article id="first-error">
                <h3>Always Fix the First Error</h3>
                <div class="meta">Tag: Philosophy | Impact: Root Cause Accuracy</div>
                <p>I’ve seen engineers waste days chasing error #405. I tell them: **Stop. Go back to error #1.** Usually, everything else is just a cascading failure from the original fault.</p>
            </article>

            <article id="count-oks">
                <h3>Count the Ok's</h3>
                <div class="meta">Tag: Philosophy | Impact: Statistical Yield</div>
                <p>In high-volume manufacturing, "Pass" isn't enough. We need to know *how much* it passed by. I advocate for margin testing—don't just check if it's 'OK', check if it's 'Barely OK'.</p>
            </article>

            <article id="conflict-management">
                <h3>The Conflict Management Lesson</h3>
                <div class="meta">Tag: Leadership | Impact: Team Cohesion</div>
                <p>Early in my career, I was too focused on being "right." I learned that technical truth is useless if you can't communicate it without alienating your peers. Now, I focus on the "Data First" approach to resolve technical disputes.</p>
            </article>

            <article id="general-thoughts">
                <h3>General Thoughts & Philosophy</h3>
                <div class="meta">Tag: Philosophy | Impact: Engineering Culture</div>
                <ul class="phil-list">
                    <li><strong>Content is King:</strong> Automation is Queen but Content is King. This mantra focused our team. Don't let frameworks overshadow actually getting things done.</li>
                    <li><strong>Can AI Really Think?</strong> Question needs to shift from 'can it think?' to ‘Can thoughts live on paper?’ Yes. Language is the single most important invention created by humanity.</li>
                    <li><strong>2 and 7 Year Cycles:</strong> Roughly every 7 years I reinvent myself. Projects tend to finish by two years.</li>
                    <li><strong>Chopstick Coding:</strong> The concept of developing at arms length (i.e. through a serial port, over SSH etc). Doing so is difficult, like typing on a keyboard with chopsticks.</li>
                    <li><strong>Meetings:</strong> Inversely proportional to how many people attend.</li>
                    <li><strong>Lab Viking:</strong> The final stage is a Lab Viking, your job is to pillage, the lab is your oyster.</li>
                    <li><strong>Communication:</strong> Don't reply hot, or on mobile, voice is best.</li>
                </ul>
            </article>
        </section>

        <!-- FUTURE WORK -->
        <section id="future">
            <h2 class="section-title">The Horizon</h2>
            <article id="future-work">
                <h3>WIP Items</h3>
                <p>Current research focus: Multi-agent consensus for silicon error reproduction. Using RL to find the fastest path to a "Hang" state.</p>
            </article>
        </section>

    </main>

    <script src="mission-control.js?v=bd431d08"></script>
    <script src="script.js?v=7704e669"></script>
</body>
</html>